# -*- coding: utf-8 -*-
"""Text Generation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-BdB29otpsZ-umF8Kuc1nJkcjuAxDD7k
"""

tf.train.latest_checkpoint(checkpoint_dir)

model = build_model(vocab_size , embedding_dim, rnn_units , batch_size=1)
model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
model.build(tf.TensorShape([1,None]))

model.summary()

def generate_text(model , context_string,num_generate=100, temperature = 1.0):
  input_eval = [char2idx[s] for s in context_string ]
  input_eval = tf.expand_dims(input_eval , 0)

  text_generated = []
  model.reset_states()
  for i in range(num_generate):
    predictions = model(input_eval)
    predictions = tf.squeeze(predictions , 0)

    predictions = predictions / temperature
    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
    input_eval = tf.expand_dims([predicted_id] , 0)
    text_generated.append(idx2char[predicted_id])
  return (context_string + ''.join(text_generated))

print(generate_text(model , context_string="I am going to ",num_generate=20 , temperature=0.1))

print(generate_text(model , context_string="How are  ",num_generate=30 , temperature=0.1))

print(generate_text(model , context_string="Who is ",num_generate=50 , temperature=0.3))

print(generate_text(model , context_string="I will",num_generate=30 , temperature=1.0))

print(generate_text(model , context_string="Can I get a ",num_generate=100 , temperature=0.1))

print(generate_text(model , context_string="Watson you are",num_generate=75 , temperature=0.2))

print(generate_text(model , context_string="I dont  ",num_generate=30 , temperature=2.0))